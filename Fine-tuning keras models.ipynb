{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amateur-family",
   "metadata": {},
   "source": [
    "# Optimisation\n",
    "\n",
    "Hard to accomplich:\n",
    "1. In neural networks, we optimise 1000s of weights simultaneously\n",
    "2. Small learning rates may not improve our models\n",
    "3. Too large learning rates might take us too far\n",
    "\n",
    "\n",
    "The easiest way to see the effect of different learning rates is to use the simpliest optimiser: Stochastic Gradient Descent (SGD).\n",
    "SGD uses a fixed learning rate (around 0.01 is commonly used), but we can specify our own learning rates by passing lr argument into the optimiser.\n",
    "\n",
    "![](Image/Image1.jpg)\n",
    "\n",
    "Even if we have an optimal learning rate, we may encounter \"Dying Neuron Problem\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-messaging",
   "metadata": {},
   "source": [
    "## Dying Neuron problem\n",
    "\n",
    "Occurs when a neuron takes a negative value for all rows of the data.\n",
    "\n",
    "\n",
    "For ReLU function, negative input values produce outputs of 0. At this point, the slope is 0 as well.\n",
    "\n",
    "![](Image/Image2.jpg)\n",
    "\n",
    "Because of the slope is 0, the slope of any weight flowing into this node is also 0 (according to back-propagation). Then those weights won't get updated.\n",
    "\n",
    "因此，如果一次forward propagation的時候全部的input都是負數，則此node將不再有用 (dead neuron)\n",
    "\n",
    "為了避免此問題發生，可用沒有0 slope的activation function，例如：\n",
    "tanh() function\n",
    "![](Image/Image3.jpg)\n",
    "\n",
    "然而，圖中可以看到距離原點較遠的地方，其slope很小(趨近於0)，因此如果經過很多次back-propagation，讓很多很小的slope相乘，則每次weight的更新量趨近於0。\n",
    "\n",
    "#### --> 這稱作 Vanishing Gradient Problem\n",
    "\n",
    "這些問題表示我們使用的activation function不應該有太小的slope。同時，如果發現訓練結果不如預期，也可以換個activation function看看"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-federation",
   "metadata": {},
   "source": [
    "# Model Validation\n",
    "\n",
    "1. Few people run k-fold Cross Validation in deep learning because deep learning is widely used on large datasets, so CV is time consuming.\n",
    "2. A single validation is effective enough because those validation runs are reasonably large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-prairie",
   "metadata": {},
   "source": [
    "Specify validation split (testing data size) in the fitting stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prospective-explosion",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-a4a10c8c6099>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-a4a10c8c6099>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    model.fit(predictors, target, validation_split = 0.3\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(predictors, target, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-driving",
   "metadata": {},
   "source": [
    "結果的example\n",
    "\n",
    "![](Image/Image4.jpg)\n",
    "\n",
    "Stop training when the validation accuracy isn't improving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-english",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "\n",
    "![](Image/Image5.jpg)\n",
    "\n",
    "Pass a 'patience' argument **(代表如果我的validation accuracy不再大量進步時，我還要跑幾個Epoch才會停止訓練模型)** to a function called \"EarlyStopping\". Patience = 2 or 3 is good enough，太大就代表跑很多次無意義的計算。\n",
    "\n",
    "We pass the \"EarlyStopping\" object into the model fitting stage to an argument call \"callbacks\"\n",
    "\n",
    "**重點：** argument callback 為傳入一個list, 代表可以同時傳入其他控制訓練的物件(更進階)。同時代表EarlyStopping物件要放在list (\"[]\")裡面\n",
    "\n",
    "另一方面，keras的default epoch number為10次，我們可以傳入參數nb_epoch = 20來變成20次，之後直接停止。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-anime",
   "metadata": {},
   "source": [
    "# 尋找最佳模型\n",
    "\n",
    "![](Image/Image6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-machine",
   "metadata": {},
   "source": [
    "## Model Comparison Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-madonna",
   "metadata": {},
   "source": [
    "### 1 input layer + 1 hidden layer + 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-scanner",
   "metadata": {},
   "source": [
    "### 1 input layer + 2 hidden layer + 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation = 'relu', input_shape = input_shape))\n",
    "model_2.add(Dense(50, activation = 'relu'))\n",
    "model_2.add(Dense(50, activation = 'relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-rough",
   "metadata": {},
   "source": [
    "# Model Capacity (Network Capacity)\n",
    "\n",
    "![](Image/Image7.jpg)\n",
    "\n",
    "Adding layers or neurons in layers will increases model capacity.\n",
    "\n",
    "A good procedure:\n",
    "1. Start with a simple or small network, get its validation score\n",
    "2. Keep adding capacities if the score increases\n",
    "3. Stop adding capacities if the score starts to decrease\n",
    "\n",
    "**Example:**\n",
    "\n",
    "![](Image/Image8.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-trade",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
